import streamlit as st

# D콡LE콯IT칄: set_page_config mus칤 b칳t prvn칤 Streamlit p콏칤kaz v aplikaci
st.set_page_config(
    page_title="Analytick칳 n치stroj pro pr치ce 쮂멺콢",
    page_icon="游늵",
    layout="wide",
    initial_sidebar_state="expanded"
)

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# St치hnout pot콏ebn칠 bal칤캜ky NLTK p콏i prvn칤m spu코t캩n칤
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

# Funkce pro p콏edzpracov치n칤 textu
def preprocess_text(text):
    if not isinstance(text, str):
        return ""
    # P콏evod na mal치 p칤smena
    text = text.lower()
    # Odstran캩n칤 interpunkce a 캜칤sel
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    # Odstran캩n칤 extra mezer
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# Funkce pro v칳po캜et podobnosti text콢
def calculate_similarity(text1, text2, method='cosine'):
    # P콏edzpracov치n칤 text콢
    processed_text1 = preprocess_text(text1)
    processed_text2 = preprocess_text(text2)
    
    # V칳b캩r metody pro vektorizaci
    if method == 'tfidf':
        vectorizer = TfidfVectorizer()
    else:  # v칳choz칤 metoda je 'cosine'
        vectorizer = CountVectorizer()
    
    # Vektorizace text콢
    try:
        vectors = vectorizer.fit_transform([processed_text1, processed_text2])
        # V칳po캜et podobnosti
        similarity = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]
        return similarity
    except Exception as e:
        st.error(f"Chyba p콏i v칳po캜tu podobnosti: {e}")
        return 0

# Funkce pro porovn치n칤 kl칤캜ov칳ch slov
def compare_keywords(text1, text2, top_n=10):
    # P콏edzpracov치n칤 text콢
    processed_text1 = preprocess_text(text1)
    processed_text2 = preprocess_text(text2)
    
    # Z칤sk치n칤 stop slov (nerelevantn칤ch slov)
    try:
        stop_words = set(stopwords.words('czech'))
    except:
        stop_words = set()  # Pokud nen칤 dostupn치 캜e코tina, pou쬴jeme pr치zdnou mno쬴nu
    
    # Tokenizace a odstran캩n칤 stop slov
    words1 = [word for word in word_tokenize(processed_text1) if word not in stop_words and len(word) > 1]
    words2 = [word for word in word_tokenize(processed_text2) if word not in stop_words and len(word) > 1]
    
    # Po캜칤t치n칤 frekvence slov
    word_freq1 = pd.Series(words1).value_counts().head(top_n)
    word_freq2 = pd.Series(words2).value_counts().head(top_n)
    
    return word_freq1, word_freq2

# Funkce pro anal칳zu d칠lky textu
def analyze_length(text1, text2):
    if not isinstance(text1, str) or not isinstance(text2, str):
        return {"text1": 0, "text2": 0, "diff_percent": 0}
    
    # Po캜et slov
    words1 = len(re.findall(r'\b\w+\b', text1))
    words2 = len(re.findall(r'\b\w+\b', text2))
    
    # Rozd칤l v procentech
    if words1 > 0:
        diff_percent = ((words2 - words1) / words1) * 100
    else:
        diff_percent = 0
    
    return {
        "text1": words1,
        "text2": words2,
        "diff_percent": diff_percent
    }

# Hlavn칤 nadpis aplikace
st.title("游댌 Analytick칳 n치stroj pro porovn치v치n칤 쮂멺ovsk칳ch prac칤")
st.write("Tento n치stroj umo쮄갓je porovnat pr치ci 쮂멺a se vzorov칳m 콏e코en칤m a analyzovat podobnosti a rozd칤ly.")

# Vytvo콏en칤 z치lo쬰k pro r콢zn칠 typy anal칳z
tab1, tab2 = st.tabs(["Textov치 anal칳za", "Nastaven칤"])

with tab1:
    col1, col2 = st.columns(2)
    
    with col1:
        st.header("Vzorov칠 콏e코en칤")
        reference_text = st.text_area("Vlo쬾e vzorov칳 text", height=250)
    
    with col2:
        st.header("Pr치ce 쮂멺a")
        student_text = st.text_area("Vlo쬾e text 쮂멺a", height=250)
    
    # Tla캜칤tko pro proveden칤 anal칳zy
    if st.button("Prov칠st anal칳zu"):
        if reference_text and student_text:
            st.divider()
            st.header("V칳sledky anal칳zy")
            
            # V칳po캜et podobnosti
            similarity = calculate_similarity(reference_text, student_text)
            st.metric("M칤ra podobnosti", f"{similarity*100:.2f}%")
            
            # Anal칳za d칠lky textu
            length_analysis = analyze_length(reference_text, student_text)
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Po캜et slov ve vzoru", length_analysis["text1"])
            with col2:
                st.metric("Po캜et slov v pr치ci 쮂멺a", length_analysis["text2"])
            with col3:
                diff_label = "Rozd칤l d칠lky"
                diff_value = f"{length_analysis['diff_percent']:.2f}%"
                diff_delta = f"{'+' if length_analysis['diff_percent'] > 0 else ''}{length_analysis['diff_percent']:.2f}%"
                st.metric(diff_label, diff_value, diff_delta)
            
            # Porovn치n칤 kl칤캜ov칳ch slov
            st.subheader("Porovn치n칤 kl칤캜ov칳ch slov")
            keywords1, keywords2 = compare_keywords(reference_text, student_text)
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**Nej캜ast캩j코칤 slova ve vzoru:**")
                for word, count in keywords1.items():
                    st.write(f"- {word}: {count}x")
            
            with col2:
                st.write("**Nej캜ast캩j코칤 slova v pr치ci 쮂멺a:**")
                for word, count in keywords2.items():
                    st.write(f"- {word}: {count}x")
            
            # Spole캜n치 a chyb캩j칤c칤 slova
            common_words = set(keywords1.index).intersection(set(keywords2.index))
            missing_words = set(keywords1.index).difference(set(keywords2.index))
            extra_words = set(keywords2.index).difference(set(keywords1.index))
            
            col1, col2 = st.columns(2)
            with col1:
                st.write("**Spole캜n치 kl칤캜ov치 slova:**")
                for word in common_words:
                    st.write(f"- {word}")
            
            with col2:
                st.write("**Chyb캩j칤c칤 kl칤캜ov치 slova:**")
                for word in missing_words:
                    st.write(f"- {word}")
            
            st.write("**Nadbyte캜n치 kl칤캜ov치 slova v pr치ci 쮂멺a:**")
            for word in extra_words:
                st.write(f"- {word}")
        else:
            st.warning("Pro proveden칤 anal칳zy je t콏eba vyplnit oba texty.")

with tab2:
    st.header("Nastaven칤 anal칳zy")
    st.write("Zde m콢쬰te upravit parametry anal칳zy.")
    
    # Nastaven칤 anal칳zy
    st.subheader("Parametry textov칠 anal칳zy")
    similarity_method = st.selectbox(
        "Metoda v칳po캜tu podobnosti",
        options=["cosine", "tfidf"],
        index=0,
        help="Kosinov치 podobnost je standardn칤 metoda. TF-IDF d치v치 v캩t코칤 v치hu m칠n캩 캜ast칳m slov콢m."
    )
    
    keyword_count = st.slider(
        "Po캜et kl칤캜ov칳ch slov pro porovn치n칤",
        min_value=5,
        max_value=30,
        value=10,
        step=1
    )
    
    st.info("Tato nastaven칤 budou pou쬴ta p콏i dal코칤 anal칳ze. Zm캩ny se projev칤 po stisknut칤 tla캜칤tka 'Prov칠st anal칳zu'.")

# Postrann칤 panel s n치pov캩dou
with st.sidebar:
    st.header("N치pov캩da")
    st.write("""
    **Jak pou쮂셨at tento n치stroj:**
    
    1. Vlo쬾e vzorov칠 콏e코en칤 do lev칠ho textov칠ho pole
    2. Vlo쬾e pr치ci 쮂멺a do prav칠ho textov칠ho pole
    3. Klikn캩te na tla캜칤tko 'Prov칠st anal칳zu'
    4. Prozkoumejte v칳sledky anal칳zy
    
    **Co v칳sledky znamenaj칤:**
    
    - **M칤ra podobnosti**: Hodnota mezi 0-100%, kde vy코코칤 hodnota znamen치 v캩t코칤 podobnost text콢
    - **Po캜et slov**: Porovn치n칤 d칠lky text콢
    - **Kl칤캜ov치 slova**: Nej캜ast캩j코칤 d콢le쬴t치 slova v obou textech
    - **Spole캜n치 slova**: Kl칤캜ov치 slova obsa쬰n치 v obou textech
    - **Chyb캩j칤c칤 slova**: Kl칤캜ov치 slova ze vzoru, kter치 chyb칤 v pr치ci 쮂멺a
    """)
    
    st.divider()
    st.write("춸 2025 Analytick칳 n치stroj pro porovn치v치n칤 prac칤")
